Today I made a few fixes to the LLaMA.cpp codebase. First, I [fixed some files
in `.gitignore`](https://github.com/ggerganov/llama.cpp/pull/7996) that
shouldn't have been there. This was breaking the build in Rust crates relying on
my bindings because `cargo publish` was ignoring the files.

Next, I [fixed a crash](https://github.com/ggerganov/llama.cpp/pull/8021) caused
by `ggml_metal_supports_op` returning true for bf16 which is not supported by
the Metal backend. This was triggering an assert in the metal backend and
causing Weave to crash -- hard -- resulting in system instability requiring a
cold reboot.

With that fixed, the crash in Weave should be resolved as soon as I update the
LLaMA submodule in the bindings repo. I'll do that tomorrow. With that resolved,
almost all of the issues in the Weave issue tracker should be resolved. I'm
looking forward to the next release being a stable one. There are still bugs in
the sampling code, but that will be addressed in the `drama_llama` repo.
